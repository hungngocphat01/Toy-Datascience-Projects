{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd1e464-3741-4d25-a878-f108d9e1e2be",
   "metadata": {},
   "source": [
    "Strategy: first crawl all seiyuu _links_ from all LL animes.  \n",
    "For each seiyuu: crawl all voice roles and staff roles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82327e55-531e-449c-97b6-67b96a74ea68",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5621222-5fda-4e03-b5dd-f56c9342350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff8533-42cd-46be-aca1-3ecbdd1f098c",
   "metadata": {},
   "source": [
    "## Crawl all seiyuu links from each LL anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981d8bcb-99e9-4ab7-9503-983645238b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_anime_links = [\n",
    "    ('muse', 'https://myanimelist.net/anime/15051/Love_Live_School_Idol_Project'),\n",
    "    ('aqours', 'https://myanimelist.net/anime/32526/Love_Live_Sunshine'),\n",
    "    ('nijigasaki', 'https://myanimelist.net/anime/40879/Love_Live_Nijigasaki_Gakuen_School_Idol_Doukoukai')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43aa566c-046e-4d3a-8717-fa0d3590b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seiyuus_from_anime(url: str) -> list:\n",
    "    \"\"\"\n",
    "    Get all seiyuus from an anime.\n",
    "    \n",
    "    Param: MAL anime url.\n",
    "    Return: A list consisting of all seiyuus.\n",
    "    Each seiyuu is a dictionary, keys: ('name', 'url')\n",
    "    \"\"\"\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    all_seiyuu_cells = soup.find_all('td', {'class': 'va-t ar pl4 pr4'})\n",
    "    seiyuu_list = []\n",
    "    \n",
    "    for cell in all_seiyuu_cells:\n",
    "        name = cell.find('a').text\n",
    "        url = cell.find('a')['href']\n",
    "        seiyuu_list.append({\n",
    "            'name': name,\n",
    "            'url': url,\n",
    "        })\n",
    "    return seiyuu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d46e5d-b484-477f-9fac-aa71ef8298df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seiyuu_info(url: str, selenium_driver) -> list:\n",
    "    \"\"\"\n",
    "    Get all roles of a seiyuu, including both voicing roles and staff roles.\n",
    "    \n",
    "    Returns a list of dicts with keys: \n",
    "        - anime\n",
    "        - type [supporting/main/staff]\n",
    "        - character\n",
    "    \"\"\"\n",
    "    selenium_driver.get(url)\n",
    "    html = selenium_driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    roles = []\n",
    "    \n",
    "    all_character_rows = soup.find_all('tr', {'class': 'js-people-character'})\n",
    "    all_staff_rows = soup.find_all('tr', {'class': 'js-people-staff'})\n",
    "    \n",
    "    for row in all_character_rows:\n",
    "        # Each row consisting of 3 cols: anime img, anime details, character details, character img\n",
    "        anime_name = row.find('a', 'js-people-title').text\n",
    "        anime_url = row.find('a', 'js-people-title')['href']\n",
    "        anime_id = re.search('anime/(\\d+)/', anime_url).group(1)\n",
    "                \n",
    "        char_details_col = row.find_all('td')[2]\n",
    "        # Each char detail col has 3 divs: character name, type (main/sup), fav num\n",
    "        char_details_divs = char_details_col.find_all('div')\n",
    "        roles.append({\n",
    "            'anime': anime_name,\n",
    "            'type': char_details_divs[1].text.strip(),\n",
    "            'character': char_details_divs[0].find('a').text.strip(),\n",
    "            'anime_id': anime_id\n",
    "        })\n",
    "        \n",
    "    for row in all_staff_rows:\n",
    "        anime_name = row.find('a', 'js-people-title').text\n",
    "        anime_url = row.find('a', 'js-people-title')['href']\n",
    "        anime_id = re.search('anime/(\\d+)/', anime_url).group(1)\n",
    "        \n",
    "        roles.append({\n",
    "            'anime': anime_name,\n",
    "            'type': 'Staff',\n",
    "            'character': np.nan,\n",
    "            'anime_id': anime_id\n",
    "        })\n",
    "    return roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eed1ee1-41c4-42ab-aec2-1cc23b50d8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pile... Got  32\n",
      "Tokui, Sora... Got  110\n",
      "Kusuda, Aina... Got  32\n",
      "Uchida, Aya... Got  109\n",
      "Mimori, Suzuko... Got  217\n",
      "Nitta, Emi... Got  50\n",
      "Iida, Riho... Got  40\n",
      "Nanjou, Yoshino... Got  134\n",
      "Kubo, Yurika... Got  111\n",
      "Sakuragawa, Megu... Got  21\n",
      "Kobayashi, Aika... Got  17\n",
      "Saitou, Shuka... Got  16\n",
      "Takatsuki, Kanako... Got  14\n",
      "Aida, Rikako... Got  24\n",
      "Suzuki, Aina... Got  43\n",
      "Furihata, Ai... Got  13\n",
      "Komiya, Arisa... Got  9\n",
      "Suwa, Nanaka... Got  11\n",
      "Inami, Anju... Got  13\n",
      "Satou, Hinata... Got  10\n",
      "Tanaka, Chiemi... Got  5\n",
      "Kusunoki, Tomori... Got  31\n",
      "Kitou, Akari... Got  72\n",
      "Sagara, Mayu... Got  7\n",
      "Oonishi, Aguri... Got  7\n",
      "Maeda, Kaori... Got  21\n",
      "Murakami, Natsumi... Got  8\n",
      "Kubota, Miyu... Got  25\n",
      "Yano, Hinaki... Got  6\n",
      "Sashide, Maria... Got  6\n"
     ]
    }
   ],
   "source": [
    "seiyuus_df = pd.DataFrame()\n",
    "firefox = webdriver.Firefox()\n",
    "for group, link in ll_anime_links:\n",
    "    # Get all seiyuus from each LL anime\n",
    "    seiyuu_list = get_seiyuus_from_anime(link)\n",
    "    for seiyuu in seiyuu_list:\n",
    "        print(seiyuu['name'], end='... ')\n",
    "        seiyuu_df = pd.DataFrame(get_seiyuu_info(seiyuu['url'], firefox))\n",
    "        print('Got ', len(seiyuu_df))\n",
    "        seiyuu_df['name'] = seiyuu['name']\n",
    "        seiyuu_df['group'] = group\n",
    "        seiyuus_df = pd.concat([seiyuus_df, seiyuu_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdc4f6-0cb1-4fca-a7ce-1ead20b5e1a4",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d0c484-2612-414d-ac43-78be1267706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seiyuus_df.to_csv('seiyuu.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
